% !TEX root = main.tex

\section{Description of Submission}

\subsection{Primitive to be Thresholdized}

In this work,
we describe FROST,
a two-round threshold signature scheme that thresholdizes the EdDSA signature scheme.
In particular,
we will provide a Cat1 submission for subcategory C1.1 EdDSA signing.

\subsection{Outline of Approach}

FROST (Flexible Round-Optimized Schnorr Threshold Signatures)~\cite{KomloG20,BellareCKMTZ22} addresses the need for efficient threshold EdDSA signing operations, while improving upon the state of the art to ensure strong security properties \emph{without} limiting the parallelism of signing operations.
\liz{There are a number of concurrently secure Schnorr threshold schemes now, so this sentence could use rewording.}
FROST achieves improved efficiency in the optimistic case that no participant misbehaves.
\liz{Not clear what this sentence means.}
However, in the case where a misbehaving participant contributes malformed values during the protocol,
honest parties can identify and exclude the misbehaving participant, and re-run the protocol.
\liz{We should be rigorous somewhere about how identifiable abort is achieved.}

Here, we describe the (unoptimized) two-round version of FROST.
\liz{What is the optimized two-round version?}
However, implementations may wish to perform the first round in a batched setting,
allowing the scheme to be used in a manner where online signing requires only a single round of communication.

\subsubsection{System Model.}
We assume the following when describing FROST:

\begin{itemize}[itemsep=0.5em]
\item \textbf{Idealized Key Generation via Shamir Secret Sharing.} Key generation via Shamir Secret Sharing is an idealized operation.
\liz{What is an idealized operation?}
We assume that each participant is initialized with their respective secret key share,
the public key shares of all other participants,
and the joint public key representing the group.
\item \textbf{Coordinator Role.} We model message passing between participants
via a centralized coordinator.
The coordinator is trusted to not perform denial-of-service attacks by dropping messages,
but otherwise the coordinator is untrusted.
\end{itemize}

\subsubsection{Protocol Approach.}

FROST signing can be performed either in two online rounds,
or in one batched preprocessing round,
and a second purely online round.
\liz{Above, we say we only consider two-round FROST.}
Then, a final stage to perform aggregation is required,
at which the joint signature is output.

Note that while FROST assumes that signing nonces are used at most once, \liz{Define nonce = number used only once.}
it does \emph{not} assume that participants maintain consistent session identifiers.
Each player performs $\Sign_1$ independently,
and the coordinator does not need to pick inputs to $\Sign_2$ assuming some form of consistency of sessions.
\liz{$\Sign_1, \Sign_2$ and sessions not defined.}
%To reflect this requirement,
%we introduce the notation of $\eid$, to denote an execution identifier maintained locally by each participant.
%$\eid$ is \emph{not} consistent among all participants.

\paragraph{Round One.}
The first signing round of FROST can be performed either at the time of signing,
or as a batched operation during a pre-processing phase.
\liz{Again, not sure we should be mixing these since we don't properly define the pre-processing version.}

Each party with identifier $\partyid$ \liz{What kind of identifier?  A random string?  Public key?} samples two nonces $(r_{\partyid},  s_{\partyid}) \randpick \Zp$,
\liz{We should define any mathematical notation in a preliminaries section.}
and then derives their corresponding commitments \liz{Should define commitment.} $R_{\partyid} \gets g^{r_{\partyid}}$, $ S_{\partyid} \gets  g^{s_{\partyid}}$.
They store $(r_{\partyid}, s_{\partyid})$ in their internal state,
and output $(R_{\partyid}, S_{\partyid})$.

\paragraph{Round Two.}
All participants in a signing coalition $\coalition \subseteq \set{n}, \lvert \coalition \rvert \geq t$, \liz{$n, t$ not defined.} accept as input a message $\msg$ and a combination of commitments $\setCommit := \{ (i, R_{i}, S_{i})\}_{i \in \coalition}$ from parties in the coalition.

To begin,
each party $\partyid$ retrieves $(r_{\partyid}, s_{\partyid})$ \liz{from their internal state} such that $(R_\partyid, S_\partyid) = (g^{r_{\partyid}}, g^{s_{\partyid}})$. (The party aborts if such $(r_{\partyid}, s_{\partyid})$ does not exist.)
\liz{Are they pulling a nonce pair from a particular session as in the two-round version?}
Then, each party derives binding factors $\bindingfactor_i \gets \HashNon(i, \setCommit)$ for each party $i \in \coalition$, the group commitment $R \gets \prod_{i \in \coalition} R_{i} \cdot  S_{i}^{\bindingfactor_i}$, and the challenge \liz{This terminology isn't defined.} $c \gets \HashSig(R, \pk, m)$.
\liz{$\pk$ and hashes not defined.}
Finally, each party outputs their signature share as
$z_\partyid \gets r_{\partyid} + s_{\partyid} \cdot \bindingfactor_\partyid + c \cdot \sk_\partyid \cdot \lambda_\partyid$,
where $\lambda_\partyid$ is the Lagrange coefficient, \liz{Define.}
and deletes $(r_{\partyid}, s_{\partyid})$.


\paragraph{Combine.}
The combiner \liz{We call this the coordinator above.} derives the joint response \liz{?} $z = \sum_{i \in \coalition} z_i$.
The group commitment $R$ is derived as explained above.
The output signature $\sigma = (R,z)$ is a standard Schnorr signature.
\liz{We should be explicit about how exactly this satisfies standard verification.}

\subsubsection{Security Properties.}
\liz{Maybe say something about how security of any threshold signature scheme is defined by correctness and unforgeability.}
FROST achieves a strong notion of unforgeability under the algebraic one-more discrete logarithm (AOMDL) assumption in the random oracle model (ROM).
Intuitively, unforgeability in a threshold setting \liz{signature} guarantees that an adversary which corrupts the coordinator and up to $t-1$ signers \liz{This is the dishonest majority setting, but that's not the case for all threshold signature schemes.} cannot generate a valid signature \liz{This has not been defined.  Needs to be relative to $\pk$, for example.} for $\msg$ \liz{What $\msg$?} that has not been authorized by at least one honest signer. \liz{Authorized?}
As noticed \liz{Not really ``noticed"} by Bellare et al.~\cite{BellareCKMTZ22}, there are different levels of conditions to declare $\msg$ to be authorized (signed), which gives different security levels, and stronger conditions give stronger security guarantees.
\liz{These are only definitions for partially non-interactive schemes.  Also, we are proposing the fully two-round scheme.}

%\chelsea{It would be helpful to emphasize that basic unforgeability is achieved by $\TSUF{0}$, and that each higher level gives finer-grained guarantees.}

\medskip

\textbf{TS-UF-0.} The weakest condition, which gives the weakest unforgeability, is referred to as $\TSUF{0}$, \liz{for a threshold signature TS} considers that $\msg$ was signed as long as at least one honest party generated a signature share for $\msg$. \liz{Meaning $z_i$?} In other words, for a $\TSUF{0}$-secure scheme, the adversary cannot forge a valid signature for $\msg$ if no honest party generated a signature share for $\msg$.
$\TSUF{0}$ however does not consider the case when the adversary corrupts fewer than $(t-1)$ parties.

\medskip

\textbf{TS-UF-1.} The next level of security, $\TSUF{1}$, strengthens the above condition to requiring that at least  $(t - \numcorrupt)$ honest parties generated signature shares for $\msg$,
where $\numcorrupt$ denotes the number of corrupted parties,
such that $\numcorrupt \leq t$. \liz{See next comment.}
In other words,
$\TSUF{1}$ considers the generalized setting when the adversary corrupts fewer parties than the maximum assumed threshold $t$.
\liz{This makes it seem like an adversary could corrupt $t$ parties.}

However, $\TSUF{1}$ does not guarantee that when the honest parties generated the signature shares for $\msg$, they all had the same view, i.e., received the same second-round input.
%igning coalition and the same combinations of commitments.
  %forwarding inconsistent information to different honest parties in the second (online) round.
%combining signature shares from different signing sessions.
More precisely, for a $\TSUF{1}$-secure scheme, the corrupted coordinator can send different combinations of commitments to different honest parties for signing $\msg$ in the (online) second round,
and as long as the total number of honest parties responded is at least $(t-\numcorrupt)$, the adversary might be able to compute a valid signature for $\msg$.

%\chelsea{Wouldn't this result in a ROS attack, and thus break unforgeability altogether?}

\medskip

\textbf{TS-UF-2.}
Such a malicious behavior is prevented by $\TSUF{2}$, where
we consider $\msg$ to be signed only if at least $(t - \numcorrupt)$ honest parties generated signature shares for $\msg$ and they received the same commitment combination when generating the shares.

\medskip

\textbf{TS-UF-3.} Bellare et al.~\cite{BellareCKMTZ22} showed that FROST achieves the next level of security, $\TSUF{3}$, where the above condition is further strengthened:
we declare $\msg$ to be signed only if there exists \liz{is} a coalition $\coalition$ and $\setCommit=\{ (i, R_{i}, S_{i})\}_{i \in \coalition}$ such that not only  $(t - \numcorrupt)$ honest parties, but also all honest parties $i\in \coalition$ with \emph{correct} $(R_{i}, S_{i})$, generated signature shares \liz{?} for the same secound-round input $(\msg, \setCommit)$, where we say $(R_{i}, S_{i})$ is correct if and only if it was output by party $i$ in Round 1.\footnote{Since the coordinator was corrupted, the commitment $(R_{i}, S_{i})$ might not be one of the commitments output by honest party $i$ in Round 1.}

%Namely, for a signing session with coalition $\coalition$ and second-round input $\{ (i, R_{i,\eid}, S_{i,\eid})\}_{i \in \coalition}$,
%in additional to the above condition, it is also required that each
%$(R_{i,\eid}, S_{i,\eid})$ that is input into Round 2 is in fact a correct commitment output by honest signer $i$ in Round 1 (i.e., $(R_{i,\eid}, S_{i,\eid})$ is the first-round commitment output by signer $i$).
%\chelsea{edited this for clarity, please review to make sure it is correct.}

\medskip

\textbf{TS-UF-4.}
The strongest notion of security defined by Bellare et al.~\cite{BellareCKMTZ22} is $\TSUF{4}$, which requires that there exists \liz{is} a coalition $\coalition$ and $\setCommit=\{ (i, R_{i}, S_{i})\}_{i \in \coalition}$ such that all honest parties in $\coalition$ generated shares \liz{Shares?} for $(\msg, \setCommit)$.
$\TSUF{4}$ is a stronger condition because the size of $\coalition$ is at least $t$ and thus the number of honest parties in $\coalition$ is at least  $(t - \numcorrupt)$.
One means to achieve $\TSUF{4}$ security is by ensuring authenticity of participants' messages,
to prevent an adversary from performing integrity attacks that may result in a valid output signature but where participants' views are inconsistent during the protocol execution.

Bellare et al.~\cite{BellareCKMTZ22} showed that if we assume authenticated network channels, which guarantee that the corrupted coordinator cannot forward incorrect commitments to honest parties in the online round,
then FROST achieves $\TSUF{4}$.
However, because implementations may wish to define authenticated channels in a manner specific to their setup,
we do not define this authentication layer within this specification.
As such,
we allow implementations to choose if they wish to achieve $\TSUF{4}$ security,
and simply recommend that FROST be performed over an authenticated channel to do so.

\medskip
\textbf{Strong unforgeability.} Moreover, Bellare et al.~\cite{BellareCKMTZ22} showed that FROST is \emph{strongly} unforgeable, referred to as $\TSSUF{3}$ (or $\TSSUF{4}$ assuming authenticated channels), which, analogous to the strong unforgeability of signature schemes, guarantees that an adversary cannot forge a message-signature pair $(\msg,\sigma)$ that is not considered issued.
\liz{Issued? Authorized? Signed? Let's be consistent.}
Also, it is guaranteed that there is at most one signature $\sigma$ that can be issued for each second-round input $(\msg, \setCommit=\{ (i, R_{i}, S_{i})\}_{i \in \coalition})$, and $(\msg, \sigma)$ is considered issued only if there are \emph{sufficiently many} honest parties that generated signature shares for $(\msg, \setCommit)$.
In particular, for $\TSSUF{3}$, ``sufficiently many honest parties'' includes all honest parties $i\in \coalition$ with \emph{correct} $(R_{i}, S_{i})$, and the total number of honest parties must be at least $(t - \numcorrupt)$; for $\TSSUF{4}$, ``sufficiently many honest parties'' refers to all honest parties in $\coalition$.



%FROST is statically secure assuming fewer than $t$ parties are corrupted,
%and the algebraic one-more discrete logarithm (AOMDL) assumption holds in the random oracle model (ROM).

%TODO: add a summary here of different TS-UF levels.
