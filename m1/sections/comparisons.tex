%!TEX root = ../main.tex

\section{Choices and Comparisons}\label{section:comparisons}

We here give a rationale for design decisions and the chosen system model, as well as an explanation of known advantages and limitations compared to other options and approaches.
$\frost$ is backwards compatible with any protocol using the FIPS186-5 verifier.
This is the NIST standardised Edwards-curve Digital Signature Algorithm (EdDSA) digital signature scheme \cite{EdDSA}.
EdDSA is a variant of Schnorr signature based on twisted Edwards curves.
No changes to existing implementations of the signature format or the verifier are required.
The signing procedure, however, is changed to support threshold signers.

In \cref{table:comparisons} we compare $\frost$ with other approaches in the literature.
We limit our comparisons to other concurrently secure threshold signatures that are also backwards compatible with FIPS186-5.
This includes
\begin{itemize}
	\item An unnamed protocol by Gennaro, Jarecki, Krawczyk and Rabin \cite{GennaroJKR01}
	\item An unnamed protocol by Stinson and Strobl \cite{StinsonS01}
	\item $\mathsf{2SCHNORR}$ by Nicolosi, Krohn, Dodis, and Mazi\`eres \cite{NicolosiKDM03}
	\item $\mathsf{CLASSICS}$ and $\mathsf{ZEROS}$ by Makriyannis \cite{Makriyannis22}
	\item An unnamed protocol by Lindell \cite{Lindell22}
	\item $\mathsf{ROAST}$ by Ruffing, Ronge, Jin, Schneider{-}Bensch, and Schr{\"{o}}der \cite{RuffingRJSS22}
	\item $\mathsf{SPARKLE}$ by Crites, Komlo, and Maller \cite{CritesKM23}
	\item $\mathsf{SPRINT}$ by Benhamouda, Halevi, Krawczyk, Rabin and Ma \cite{BenhamoudaHKRM23}
	\item $\mathsf{ARTIC}$ by Komlo and Goldberg \cite{KomloG24}
	\item $\mathsf{HARTS}$ by Bacho, Loss, Stern and Wagner \cite{BachoLSW24}
\end{itemize}

There exist some multi-signature schemes in which the signature format is compatible with FIPs186-5 but the signature verifier is incompatible.
This includes
\begin{itemize}
	\item $\mathsf{MSDL}$ by Boneh, Drijvers, and Neven  \cite{BonehDN18}
	\item $\mathsf{MuSig}$ by Maxwell, Poelstra, Seurin, and Wuille \cite{MaxwellPSW19}
	\item $\mathsf{MuSig2}$ by Nick, Ruffing, and Seurin \cite{NickRS21}
	\item $\mathsf{MuSigDN}$ by Nick, Ruffling, Seurin, and Wuille \cite{NickRSW20}
\end{itemize}
We also exclude these schemes from our comparisons in this section.

\subsection{Key for \cref{table:comparisons}}\label{section:comparisons:tablekey}
We here give a key for understanding the comparisons in \cref{table:comparisons}.
Where applicable we follow the keys in the Call for Proposals.
\begin{itemize}
	\item The number of parties $n$ can either be:
	\begin{itemize}
		\item (2) ``two" for $n = 2$;
		\item (3) ``three" for $n = 3$;
		\item  (S) ``small" for $4 \leq n \leq 8$;
		\item  (M) ``medium" for $9 \leq n \leq 64$;
		\item (L) ``large" for $65 \leq n \leq 1024$;
		\item (E) ``enormous" for $n > 1024$.
	\end{itemize}
	\item The corruption proportion $f/n$ can either be:
		\begin{itemize}
			\item  (D) ``dishonest majority" for $f \geq n/2$;
			\item  (h) ``honest majority” for $f < n/2$;
			\item (H) “two-thirds honest majority” for $f < n/3$.
	\end{itemize}
	\item The assumptions can  be:
		\begin{itemize}
			\item $\dl$ ``discrete logarithm" if the $\dl$ assumption is required;
			\item $\aomdl$ ``Algebraic one more discrete logarithm" if the $\aomdl$ assumption is required.
		\end{itemize}
	\item 	The idealisation for all schemes includes the random oracle model and so this is not indicated in the table.  The additional idealisations can be:
		\begin{itemize}
			\item (G)  ``game based" for a game based security notion;
			\item (S) ``simulation" for a simulation based security notion;
			\item (AGM) ``algebraic group model" if the AGM is required.
		\end{itemize}
 	\item The liveness guarantees can be
 		\begin{itemize}
 			\item  (IA) ``identifiable abort" if cheating parties can be identified;
 			\item  (h) ``robust under honest majority” if robustness holds given $f < n/2$;
 			\item (N) ``not robust against active adversaries".
 		\end{itemize}
 	\item The adversary for all schemes we consider is active.  We write:
 		\begin{itemize}
 			\item (U)  ``unknown" for no known positive or negative adaptive result;
 			\item (H) ``half" if adaptive security is provable for $f \leq \frac{k}{2}$
 			\item (F) ``full" for full adaptivity security i.e. adaptive security if provable for $f = k - 1$.
 		\end{itemize}
 	\item The number of rounds  can either be:
 	\begin{itemize}
 		\item (2) ``two" for $2$ rounds;
 		\item (3) ``three" for $3$ rounds;
 	\end{itemize}
 	\item The distributed system and communication requirements can be ......
 	\item The key generation can be ......
\end{itemize}

\subsection{Concurrency}\label{section:comparisons:concurrency}
$\frost$ as well as all other schemes in this comparison is concurrently secure.
There are no restrictions on the number of sessions a polynomial time adversary can have open at the same time.
This is a strict requirement in the call for proposals.

\subsection{Threshold Profiles}
$\frost$ is a $k$-out-of-$n$ threshold signature that supports any $1 \leq k \leq n$.
As in the Call for Proposals \cite{} we have: $k$ is the number of participants requires to sign; $f$ is the corruption proportion; and  $n$ is the number of parties.
The number of parties is enormous ($n > 1024$) although smaller $n$ is also supported.
The corruption proportion is dishonest majority ($f \geq \frac{n}{2}$) although smaller $f$ is also supported.
$\frost$'s corruption threshold is equal to the participation-minus-1 threshold $f = k-1$.
\mary{This may not be true for potential adaptive security reduction.}


\subsection{Security Assumptions}\label{section:comparisons:security}
$\frost$ is secure under the Algebraic-One-More-Discrete-Logarithm ($\aomdl$) problem \cite{NickRS21}.
This is a falsifiable assumption that holds in the generic group model \cite{CorettiDG18,BauerFP21}.
It is strictly better than the non-falsifiable One-More-Discrete-Logarithm problem \cite{BellareNPS03} because the adversary can only query on known linear combinations of fixed challenges,
as opposed to any group element.
It is strictly worse than the discrete-logarithm $(\dl)$ assumption under which the base EdDSA signature is secure.
An adversary that solves $\dl$ can also solve $\aomdl$, but an adversary that solves $\aomdl$ cannot necessarily solve $\dl$.

$\frost$ generates EdDSA signatures which cannot be post-quantum secure, because EdDSA depends on the discrete logarithm assumption.
There is a known quantum attack against the discrete logarithm problem \cite{Shor99}.



\subsection{Security Idealisation}\label{section:comparisons:idealisation}
The security reduction for $\frost$ is given under a game-based security formulation in the programmable random oracle model.
It is expected the idealised model for any threshold protocol producing EdDSA signatures must be stronger than the standard model.
This is because there is no security reduction for EdDSA without any random oracle~\cite{PaillierV05,FischlinF13,FleischhackerJS14}

There is no known security reduction for $\frost$ in the universal composability model.
To minimise the risks of composability attacks when $\frost$ is used in larger protocols,
it is important to prefix the hash digests with appropriate domain separators.
We fully specify the recommended domain separators in this document.

\subsection{Liveness}
$\frost$ is not  robust because there are no guarantees that any given session will terminate.
If a session does not terminate then this does not effect the unforgeability security guarantees.
$\frost$ does satisfy identifiable abort.  This means that if any party does not follow the honest signing protocol then they can be actively detected and removed from future iterations of the protocol.

\mary{Say something about robust competitors.}

\subsection{Adversary}\label{section:comparisons:adversary}
$\frost$ is actively secure.  An adversary can corrupt up to $f$ parties, controlling them to arbitrarily deviate from the prescribed multi-party protocol.
There is no adaptive security reduction for $\frost$, i.e., we cannot prove security against an adversary that can decide which parties to corrupt after observing some of the protocol execution.
However there is also no known adaptive attack against $\frost$.

\mary{
	Please help, I know little about this:
	The proposed threshold schemes should be compatible with modular subprotocols / mechanisms for proactive (and reactive) recovery, which attempt to recover possibly corrupted parties back to an uncorrupted state. This is especially important to better handle a persistent mobile adversary that continuously attempts to corrupt more parties. With respect to refreshing secret shares, the solutions can be based on a modularized phase of secret-resharing (see T6), while also specifying the needed conditions (e.g., requirement of some initial/final agreement by a qualified quorum) for its integration.
}

There exist $3$ round schemes that provably fully adaptive \cite{} in the algebraic group model with non-programmable random oracles.  However there is no static or adaptive security reduction of $\frost$ in this model.

\subsection{Number of Rounds}\label{section:comparisons:rounds}
$\frost$ has $2$ signing rounds and allows the message to be determined in the second round of signing.
Thus $\frost$ allows for an effective non-interactive signing procedure assuming that a preprocessing phase is run in advance.
This is not possible for any threshold scheme producing EdDSA signatures that depends on $\dl$.

Currently there is no known efficient concurrently secure $2$-round threshold signature scheme that generates EdDSA signatures that is secure under $\dl$.
We do not know if this is fundamental or not.  However, there are efficient concurrently secure $3$-round threshold signature schemes \cite{Lindell22,Makriyannis22,CritesKM23}.
The $3$ round schemes require the message to be fixed in the first or second round of the protocol.

\subsection{Communication Complexity}\label{section:comparisons:communicationcomplexity}
A full theoretical and experimental break down of the communication complexity of $\frost$ is given in \cref{?}.
In each signing session all parties:  send $2 \Gr$ and $1 \F$; and receive $2 k \Gr$ as well as the message and signing set.

\subsection{State Management and Storage Requirements}\label{section:comparisons:statemanagement}
$\frost$ requires state management to ensure that:
(1) secret randomness from the first round is available to the signer in the second round;
(2) nonces from the first round are not used twice.
All schemes we compare against also require state management to ensure these two properties.
If the secret randomness from the first round is lost then the signer will not be able to take part in the second round.
If the nonces from the first round are used twice then an adversary can recover the signers partial secret key,
thus compromising the signer.

Unlike in FIPS186-5 it is important that nonces are not generated using deterministic randomness to prevent nonces from the first round being used twice.

As a two round scheme $\frost$ has simpler state management than the other threshold signatures we compare against.
For example $\frost$ does not need to track which round of signing each party is currently in.
There are no single round threshold signatures that product FIPS186-5 signatures.

To allow simulate non-interactive signing $\frost$ preprocesses numerous first round contributions for each signing party.
This is possible because $\frost$ signers do not learn the message or signing set until the second round.
This requires storage of the state for all (preprocessed) open sessions.
We only analyse security when the states are stored and managed exactly as specified in this document.
\mary{Check with others if this is okay.}
\liz{Is state updated, or is state maintained for each round?}

\subsection{Distributed Systems and Communication}



\subsection{Key Generation}\label{section:comparisons:keygeneration}
For simplicity we specify $\frost$ assuming a trusted setup procedure, where a single trusted user generates all key shares.
For many applications such as backups this suffices.
However  $\frost$ can be instantiated with any simulatable distributed key generation \cite{}.

\begin{table}[htbp]
	\centering
	\begin{tabular}{c c c c c c c c}
		\toprule
		Scheme & \ $n$ \ & $f/n$ & Assumption & Ideal & Live & Adversary & Rounds \\ \midrule
		GJKR01 \cite{GennaroJKR01}& & & & & & & \\
		SS01 \cite{StinsonS01} & & & & &  & & \\
		$\mathsf{2SCHNORR}$ & & & & & &  & \\
		$\mathsf{CLASSICS}$ & & & & & & & \\
		$\mathsf{ZEROS}$ & & & & & &   & \\
		Lindell22 \cite{Lindell22} & E & D & $\dl$ & S &  IA, N & U & $3$ \\
		$\mathsf{ROAST}$ & & & & &  & & \\
		$\mathsf{SPARKLE}$ & E & D & $\dl$ & G & IA, N & H & $3$ \\
		$\mathsf{SPARKLE}^*$ & E & D & $\dl$ & G, AGM & IA, N & F & $3$ \\
		$\mathsf{SPRINT}$ & & & & & &  & \\
		$\mathsf{ARTIC}$ & & & & & &  & \\
		$\mathsf{HARTS}$ & & & & & &  & \\
		\midrule
		$\mathsf{FROST}$ & E & D & $\aomdl$ & ROM & IA, N & U & $2$ \\
		\bottomrule
	\end{tabular}
	\caption{\label{table:comparisons}
		Table of comparisons with other schemes that are backwards compatible with the signature format and verifier of FIPS186-5.
		We provide a key for interpreting this table in \cref{section:comparisons:tablekey}.
	 }
\end{table}


\section{System Model}\label{section:system-model}

\subsection{Participants}
We consider a set of $n$ parties
$P_1, \dots, P_n$ and a coordinator $\mathcal{C}$, which execute the FROST signing protocol.
The coordinator may be one of the parties $P_i$ or an external party.
All parties can be modeled as probabilistic, polynomial-time Turing machines.
We assume there is prior agreement on the value of $n$ and the threshold $t$ as well as the $n$ participant identifiers (i.e., all parties ``know who" the $n$ parties are).
In implementations with authenticated channels, participant identifiers may be associated to public keys, which need to be verified, for example, by zero-knowledge proofs during key generation.
\ian{Below, we say there's no need for authenticated channels at all.
Do we need to talk about verifying keys in that case?  Later, we say
authenticated channels allow for identifiable abort, but as I note
below, that's only true sometimes.}

Note that FROST can be instantiated without the coordinator $\mathcal{C}$ by having parties multicast
\ian{Not broadcast, but rather just send their messages to each other
party.  The parties do \emph{not} need to be assured that they all
received the same messages, which is what ``broadcast'' implies, as
notes below.} \liz{Changed to multicast.}
their protocol messages instead.  However, this would result in increased communication complexity of $\BigO(\kappa n^2)$, where $\kappa$ is the security parameter.
\ian{FROST already has this complexity even in the coordinator setting,
no?  The $B$ vector of $(i,D_i,E_i)$ tuples is of length $\BigO(\kappa
n)$, and it needs to be sent to each of $n$ parties. I can believe the
\emph{message} complexity is higher in the non-coordinator setting, though.}

\subsection{Distributed Systems and Communication}


\begin{description}

\item[Synchrony.] FROST is unforgeable even in an asynchronous network. An adversary may be \emph{rushing}; that is, it may wait until all honest protocol messages have been sent before determining its own messages.

\item[Reliability.] FROST relies on a reliable network channel, meaning that all protocol messages are delivered correctly, exactly once, and in the intended order.  \liz{The NIST document says we should discuss the pitfalls of deployment in environments with weaker guarantees (e.g., with asynchronous and unreliable channels), and possible mitigations.  What are some possible mitigations against forging if the network is unreliable?}
\ian{I'm thinking that a table might be useful, showing that if you do
or don't have synchronous / reliable / confidential / authenticated /
broadcast channels, then what guarantees (correctness, robustness,
security/unforgeability, etc.) do and don't hold in each of the key generation
and signing phases?}
\liz{For table, Ian: Not needed during signing for unforgeability, but needed during key generation (recipient-authenticated and confidential for the trusted-dealer style of key generation, for example).}

\item[Broadcast Channels.] FROST does not rely on a broadcast channel; an adversary may send inconsistent protocol messages to honest parties, even within the same signing session.  

\item[Authenticated Channels.] Authenticated channels are not assumed either, so an adversary can decide which protocol messages to send to an honest party on behalf of another honest party.

\end{description}

\noindent \textbf{Robustness.} FROST is not robust, meaning that there is no guarantee that a signing session will terminate in the presence of an adversary.
However, in a slightly stronger network model, FROST does achieve identifiable aborts.
Indeed, if authenticated channels are assumed, participant identifiers may be associated to public keys via a public key infrastructure (PKI).
Then, if a signer produces a malformed protocol message, they may be identified and removed from the signing session, and a new FROST session may be initiated without them.
\ian{This doesn't look sufficient to me to yield identifiable abort?
What if the coordinator equivocates (sends different messages to
different parties), for example?  You'd need some broadcast-esque
subprotocol for honest signers to identify an equivocating coordinator.}
\liz{I wrote Tim that that identifiable abort technically requires broadcast, and his response was, ``It achieves IA precisely in the sense of our Def. 2.2. If you're saying that IA without broadcast is impossible because honest parties can't agree on the bad party, then the coordinator acts as a broadcast channel and takes care of this."  Another paper, Glacius, gives a game-based definition of IA (pg. 9 of https://eprint.iacr.org/2024/1628.pdf), and says, ``We note that our IA property differs from the IA property in the secure multiparty computation (MPC) literature. In the MPC literature, the IA property must also detect parties who fail to send
required protocol messages. In contrast, our IA property focuses solely on detecting explicit misbehavior,
not crash failures. The IA in MPC literature is stronger, but achieving this property requires broadcast
channels and, consequently, imposes constraints on failure bounds and network conditions. Contrary to this,
our IA definition is agnostic to network conditions and fault-tolerance levels."}
This trivially results in a robust scheme; however, as noted in \cite{RuffingRJSS22}, if there are $f$ malicious
signers, then $f+1$ sequential runs of the underlying protocol are required, which are necessarily synchronous.
\ian{And for the coordinator to be honest, in order to properly exclude
the misbehaving players and re-execute the protocol.  But is synchrony
actually needed here?  Won't the messages of the subsequent rounds of
the protocol just get there when they get there?  As long as the network
is authenticated and \emph{reliable} (and the coordinator and enough
signers are honest), this should yield robustness and unforgeability,
right?}
\liz{ROAST specifically requires a scheme with identifiable aborts.  The application of ROAST (a wrapper) to such a protocol yields a robust scheme that maintains asynchrony.  I am not sure why the trivially robust scheme is cited as requiring synchrony.  I will write Tim about this.}

\subsection{Adversary}

A threshold signature scheme is said to be \emph{secure} if, with overwhelming probability, an adversary cannot forge a threshold signature.

\begin{description}

\item[Active.] FROST is secure against an active adversary who may corrupt up to $f = t-1$ out of a threshold of $t$ parties (where $t \leq n$), controlling them to arbitrarily deviate from the prescribed multi-party protocol.   As described in Section~\ref{sec:unforgeability}, FROST achieves TS-(S)UF-3 security~\cite{BellareCKMTZ22} (without authenticated channels).

\item[Adaptive.] The stronger adaptive adversary is able to decide which parties to corrupt after observing some of the protocol execution.
Upon corruption, the adversary learns the secret key and private state for the corrupted party in all open signing sessions.
Currently, there is no known proof of adaptive security for FROST.

\item[Mobile.] A mobile adversary ``persistently continues (attempting to) corrupt parties across multiple executions of the main protocol, possibly corrupting parties after they have been recovered from a previous corruption."
\ian{Cite that this quote is from the call.}
\liz{This quote has been removed, and the discussion of mobile adversaries has changed. ``The suggestion to consider a mobile adversary is intended to
induce the characterization of various levels of insecurity (e.g., which properties break)
when acceptable thresholds are surpassed. In practice, the adversary’s capabilities may be
modeled as part of the security idealization (see Appendix C.2.3)." Then: ``Compatibility with recovery mechanisms (against mobile attacks). A submit-1142
ted threshold scheme is not required to include recovery mechanisms that attempt1143
to identify, remove or replace (recover) corrupted parties. However, the submission1144
should discuss how it envisions possible augmentations to integrate mechanisms1145
for proactive or reactive recovery, which are important for handling a persistent1146
mobile adversary that continuously attempts to corrupt more parties. For example,1147
with respect to refreshing secret shares, a solution can be based on a modularized1148
phase of secret-resharing (see S7), while also specifying the needed conditions (e.g.,1149
requirement of some initial/final agreement by a qualified quorum) for its integration."}
Currently, there is no known security proof for FROST capturing a mobile adversary.
\liz{Dynamic-FROST (https://eprint.iacr.org/2024/896) possibly achieves this.}
\ian{But not for FROST as specified in our submission, right?  It needs
to add CHURP in order to achieve security against a mobile adversary?
(\emph{Some} kind of proactivity is pretty much unavoidable if you want
to defend against a mobile adversary.)}

\end{description}

\subsection{Clarification of Prior Work}

\paragraph{An enumeration of the building blocks, techniques and ideas known to have been developed or authored in prior work and that are used in the specification of the primitives and threshold schemes of the present submission. With regard to the building blocks, techniques and ideas in the submission (preferably including hyper-references to the related portions of the submitted specification), this section should aim to clarify and distinguish between (i) those that may have been designed by authors that are not part of the submitters’ team, (ii) those that may have been previously developed/authored by members of the submitters’ team, and (iii) those that may be original in the present submission. Appropriate bibliographic references should be given where applicable, preferably including (when possible) a hyperlink to online-accessible documentation. If applicable, this section can also include known information pertinent to the “call for patent claims.”}
%
%The classic security proof for Schnorr signatures uses rewinding under the discrete logarithm (DL) assumption in the ROM \cite{PointchevalS00}, and static security of a variety of key-unique threshold Schnorr signature schemes using rewinding in the ROM have been shown under the discrete logarithm (DL) assumption~\cite{KomloG20,CritesKM23} and the (interactive) OMDL assumption \cite{BellareCKMTZ22,CritesKM21,RuffingRJSS22,ChuGRS23}.
%
%The purpose of the aggregation algorithms SignAgg and SignAgg′ is to enable savings in the
%broadcast communication in both signing rounds: An aggregator node [SS01; KG20], which will be
%untrusted in our security model and can for instance be one of the signers, can collect the outputs
%of all signers in both rounds, aggregate the outputs using SignAgg and SignAgg′, respectively, and
%broadcast only the aggregate output back to all signers. This optimization is entirely optional. If it
%is not desired, each signer can simply broadcast its outputs directly to all signers, which then all
%run SignAgg and SignAgg′ by themselves.
%
%Table: multi-sig or threshold, online/offline rounds, static security assumptions, adaptive security assumptions, corruption threshold, rewinding?
%
$\text{ }$
\liz{We discussed reinterpreting this as mainly a clarification of potentially patented techniques/ideas.}

    \liz{We have a couple of papers with 1 author not on the submitters' team, e.g., Mihir and Al.}

\subsubsection{Directly Used Building Blocks, Techniques, and Ideas for the FROST Protocol.}

\begin{enumerate}
\item \textbf{Shamir secret sharing.}
\item \textbf{Schnorr signatures.} Schnorr introduced the eponymous signature scheme in \cite{Schnorr91}. \liz{Maybe include patents and pull from FIPS-185-6.}
\item \textbf{FROST.} Komlo and Goldberg introduced FROST, a two-round threshold Schnorr signature scheme, where the first round can be pre-processed. \liz{Define pre-processing.}
\item \textbf{FROST RFC.}
\end{enumerate}

\subsubsection{Directly Used Building Blocks, Techniques, and Ideas for Proving the Security of FROST.}

\begin{enumerate}  
\item \textbf{Discrete logarithm assumption (i).}  Diffie and Hellman~\cite{DiffieH76} defined the discrete logarithm (DL) assumption in cryptography. \liz{Definitions section?}
\item \textbf{Random oracle model (i).}  Bellare and Rogaway~\cite{BellareR93} introduced the idealized security model called the random oracle model (ROM), defined at the end of this section.  
%The static security of FROST and adaptive security up to $f/2$ corruptions have been proven in the ROM.
\item \textbf{Security of Schnorr signatures (i).}  Pointcheval and Stern~\cite{PointchevalS00} proved that the Schnorr signature scheme is existentially unforgeable under chosen-message attacks (EUF-CMA)~\cite{GoldwasserMR88} under the DL assumption in the ROM.  
%The security proof relies on the technique of rewinding.~\liz{Who invented the technique of rewinding?}
\item \textbf{General forking lemma.} Bellare and Neven~\cite{BellareN06} forking lemma (generalized, vs. what was done in PS00). 
\item \textbf{Local forking lemma.} \liz{BTZ FROST proof uses variant of the local forking lemma.  ``The extra looseness is due to needing to ensure an extra condition when rewinding."}
\item \textbf{Algebraic group model (i).}  Fuchsbauer, Kiltz, and Loss~\cite{FuchsbauerKL18} introduced the idealized security model called the algebraic group model (AGM), defined at the end of this section.  
%The adaptive security of FROST above $f/2$ corruptions has been proven in the algebraic group model (AGM) and ROM.
\item \textbf{One-more discrete logarithm assumption (i).}  Bellare, Namprempre, Pointcheval, and Semanko~\cite{BellareNPS03} defined the one-more discrete logarithm (OMDL) assumption.
\item \textbf{Algebraic OMDL assumption (i).}  Nick, Ruffing, and Seurin \liz{cite} defined the algebraic OMDL assumption.  \liz{Discussion somewhere on the difference?}
\item \textbf{FROST2 (ii).} Crites, Komlo, and Maller~\cite{CritesKM21} introduced and proved the security of a variety of two- and three-round Schnorr threshold and multi-signature schemes. \liz{Define multi-signature somewhere.} In particular, the authors proposed a three-round Schnorr multi-signature SimpleMuSig and threshold signature SimpleTSig, where the first round can be pre-processed.  Key generation for SimpleTSig is performed using the DKG in~\cite{KomloG20}. \liz{Say more on this.} The authors proved the security of both schemes under the DL assumption in the ROM. \liz{Not strictly true.  Schnorr + SchnorrKoE.  Say more on this.}  They then proposed a two-round Schnorr multi-signature SpeedyMuSig and an optimized version of FROST, called FROST2, which reduced the number of exponentiations required for signing and verification from $t$ to one.  \liz{Discussion of the FROST variants somewhere.} Key generation is likewise performed using the DKG in~\cite{KomloG20}.
``They prove that FROST2 with PedPop is unforgeable in the ROM under the OMDL assumption and under the Schnorr
knowledge of exponent assumption (Schnorr-KoE), which they introduce and justify in the algebraic group model (AGM)."
\item \textbf{BTZ22 (ii).} Bellare, Tessaro, and Zhu~\cite{BellareTZ22} proved the security of FROST and FROST2, assuming key generation is performed using a trusted key generation algorithm.  FROST is proven strongly unforgeable (TS-SUF-3 secure) under the OMDL assumption in the ROM. FROST is proven strongly unforgeable (TS-SUF-2 secure) under the same assumptions.  \liz{Talk about hierarchy somewhere?}
\item \textbf{BCKMTZ22 (ii).} Bellare, Crites, Komlo, Maller, Tessaro, and Zhu~\cite{BellareCKMTZ22} is the merge of \cite{BellareTZ22} and FROST2 from \cite{CritesKM21}.
\item \textbf{Security of Schnorr signatures in the AGM (i).}  Fuchsbauer, Plouviez, and Seurin~\cite{FuchsbauerPS20} proved the EUF-CMA security of Schnorr signatures under the DL assumption in the AGM and ROM. \liz{Discussion of tightness somewhere?}
\item \textbf{Sparkle+ (ii).} Crites, Komlo, and Maller~\cite{CritesKM23} presented Sparkle+, a three-round threshold Schnorr signature scheme with one round of pre-processing.  The authors showed that Sparkle+ achieves several levels of security based on different corruption models and assumptions.  Specifically, they demonstrate that Sparkle+ is secure against (1) static corruption in the random oracle model if the discrete logarithm problem is hard, (2) $f/2$ adaptive corruption in the random oracle model if the AOMDL problem is hard, and (3) adaptive corruption of a full $f$ parties in the AGM and ROM if the AOMDL problem is hard.  The adaptive security proofs do not rely secure erasure of secret state or the guessing argument \liz{Refer to section in NIST document that bans the guessing argument, page 72 of new NIST call.}  \liz{To Do: Update Sparkle+ full adaptive claim and add Sparkle later.} 
\item \textbf{A plausible attack on adaptive security (ii).}  Crites and Stewart show that a large class of threshold Schnorr signature schemes, including FROST, cannot be proven adaptively secure for corruption thresholds above $f/2$ without additionally assuming the hardness of new computational (search) problem, which they define.
\item \textbf{Adaptive security of FROST (ii).}  Crites, Katz, Komlo, Tessaro, and Zhu define the computational assumption needed to prove FROST adaptively secure above $f/2$ corruptions, called the low-dimensional vector representation (LDVR) assumption.  FROST is secure against (1) $f/2$ adaptive corruption in the ROM  if the AOMDL problem is hard, and (2) adaptive corruption of a full $f$ parties in the AGM and ROM if the AOMDL and LDVR problems are hard.  The adaptive security proofs do not rely secure erasure of secret state or the guessing argument.
In the same work, the authors proved the static security of FROST under the algebraic one-more discrete logarithm assumption in the ROM.
\end{enumerate}

\parhead{Random Oracle Model~\cite{BellareR93}}. The random oracle model is an idealized model that treats a hash function $\Hash$ as an oracle in the following way.  When queried on an input in the domain of $\Hash$, the oracle first checks if it has an entry stored in its table for this input.  If so, it returns this value.  If not, it samples an output in the codomain of $\Hash$ uniformly at random, stores the input-output pair in its table, and returns the output.

\parhead{Algebraic Group Model~\cite{FuchsbauerKL18}}. The algebraic group model is an idealized model that places the following restriction on the computation of the adversary. An adversary is \emph{algebraic} if for every group element $Z \in \Gr = \langle g \rangle$ that it outputs, it is required to output a representation $\vec{a} = (a_0, a_1, a_2, \dots)$ such that $Z = g^{a_0} \prod {Y_i}^{a_i}$, where $Y_1, Y_2, \dots \in \Gr$ are group elements that the adversary has seen thus far.
Intuitively, this captures the notion that an algorithm should know how it computes its outputs from the values it has received as input so far.
The AGM is reminiscent of the generic group model (GGM), but lies somewhere between it and the standard model.

\subsubsection{Related Work - Not Directly Used}

\begin{enumerate}
\item Stinson and Strobl~\cite{StinsonS01} constructed \liz{the first?} threshold Schnorr signature scheme and proved it secure in the random oracle model under the discrete logarithm assumption. Signing requires performing a three-round distributed key generation protocol (DKG)~\cite{GennaroJKR07} \liz{Confirm we want this citation for defining DKG.} to generate the nonce for each signature, followed by one round to issue signature shares. \liz{Exactly 4 rounds? Say something about network assumptions?  FROST uses the technique of the coordinator node from SS01.}
% ROAST cites SS01 and FROST only for coordinator node
\item Abe and Fehr~\cite{AbeF04} constructed a threshold Schnorr signature scheme also by using a three-round DKG for nonce generation.
For security, they assume that the majority of parties are honest (i.e., $f < n/2$) and prove their scheme secure against up to $f$ adaptive corruptions. \liz{In the ROM under DL? What about static security? They also require strong network assumptions (synchronous broadcast).}
\item Gennaro, Jarecki, Krawczyk and Rabin~\cite{GennaroJKR01} \liz{To Do: Differentiate the 3 GJKR papers.} proposed a threshold Schnorr signature scheme that was shown not to be secure under concurrent signing sessions.  Requires a synchronous network for unforgeability.
\item \textbf{MuSig.} (original and fix)
\item \textbf{ROS attack papers.} 2003,\cite{cryptoeprint:2018/417,DrijversEFKLNS19}, BLORR21. 
\item \textbf{DWMS.} Alper and Burdges~\cite{AlperB21} introduced the Delinearized Witness Multi-Signature (DWMS), a two-round Schnorr multi-signature (i.e., requiring $n$-out-of-$n$ signers), where the first round can be pre-processed.  They proved security in the random oracle model and algebraic group model under the one-more discrete logarithm assumption (OMDL) and the 2-entwined sum problem, a hardness problem that they introduce and prove in the algebraic group model under the discrete logarithm assumption.
\item \textbf{MuSig2.} Concurrently and independently, Nick, Ruffing, and Seurin introduced MuSig2~\cite{NickRS21}, the same construction as in \cite{AlperB21}, and prove security in the random oracle model and algebraic group model under the one-more discrete logarithm assumption \liz{Updated to AOMDL}.  They provide a second, slightly less efficient protocol that is proven secure in the random oracle model under OMDL using rewinding.
AOMDL
\item \textbf{ROAST: FROST3.} \liz{Ideas not used? Or yes, for identifiable aborts/robustness?}
\item \textbf{Olaf}
\end{enumerate}
