% !TEX root = main.tex

\section{Description of Submission}

\subsection{Primitive to be Thresholdized}

In this work,
we describe FROST,
a two-round threshold signature scheme that thresholdizes the EdDSA signature scheme.
In particular,
we will provide a Cat1 submission for subcategory C1.1 EdDSA signing.

\subsection{Outline of Approach}

FROST (Flexible Round-Optimized Schnorr Threshold Signatures)~\cite{KomloG20,BellareCKMTZ22} addresses the need for efficient threshold EdDSA signing operations,
while ensuring strong security properties \emph{without} limiting the parallelism of signing operations.
FROST signing operations can be performed in two network rounds assuming no participant misbehaves.
However, in the case where a misbehaving participant contributes malformed values during the protocol,
honest parties can identify and exclude the misbehaving participant, and re-run the protocol.
%\liz{We should be rigorous somewhere about how identifiable abort is achieved.}

Here, we describe the two-round version of FROST.
However, implementations may perform the first round in a batched setting,
allowing the scheme to be used in a manner where online signing requires only a single round of communication.

\subsubsection{System Model.}
We assume the following when describing FROST:

\begin{itemize}[itemsep=0.5em]
\item \textbf{Idealized Key Generation via Shamir Secret Sharing.}
We model key generation as an idealized functionality that outputs Shamir secret shares $\sk_i$ of a private signing key corresponding to a public key $\pk$,
where $n$ total parties receive a secret signing share,
and $\thresh$ parties are required to reconstruct.
We assume that each participant is initialized with their respective secret key share,
the public key shares of all other participants,
and the joint public key representing the group.
\item \textbf{Coordinator Role.} We model message passing between participants
via a centralized coordinator.
The coordinator is trusted to not perform denial-of-service attacks by dropping messages,
but otherwise the coordinator is untrusted.
\end{itemize}

\subsubsection{Protocol Approach.}

FROST signing can be performed either in two online rounds,
or one online round,
after performing the first round using matching.
and a second purely online round.
Then, a final stage to perform aggregation is required,
at which the joint signature is output.
The scheme is defined with respect to the domain-separated hash functions $\HashNon$ and $\HashSig$.

Note that while FROST assumes that randomness generated during the first round of signing is used at most once during the second round of signing,
it does \emph{not} assume that participants maintain consistent session identifiers.
Each player performs the first round of signing independently,
and the coordinator does not need to pick inputs to the second round of signing,
assuming some form of consistency of sessions.
%To reflect this requirement,
%we introduce the notation of $\eid$, to denote an execution identifier maintained locally by each participant.
%$\eid$ is \emph{not} consistent among all participants.

\paragraph{Round One.}
The first signing round of FROST can be performed either at the time of signing,
or as a batched operation during a pre-processing phase.
%\liz{Again, not sure we should be mixing these since we don't properly define the pre-processing version.}
% CK- we don't need to define the pre-processing setting;
% the first round is just done as a batched operation.

Each party with identifier $\partyid \in \{ 1, \ldots, n\} $ where $n \in \Zp$ is the total number of parties
samples two nonces $(r_{\partyid},  s_{\partyid}) \randpick \Zp$,
%\liz{We should define any mathematical notation in a preliminaries section.}
% CK- this is just an abstract, I think it is ok.
and then derives the corresponding commitments $R_{\partyid} \gets g^{r_{\partyid}}$, $ S_{\partyid} \gets  g^{s_{\partyid}}$.
They store $(r_{\partyid}, s_{\partyid})$ in their internal state,
and output $(R_{\partyid}, S_{\partyid})$.

\paragraph{Round Two.}
All participants in a signing coalition $\coalition \subseteq \set{n}, \lvert \coalition \rvert \geq \thresh$,
accept as input a message $\msg$ and a combination of commitments $\setCommit := \{ (i, R_{i}, S_{i})\}_{i \in \coalition}$ from parties in the coalition.

On input the message $m$ and commitment set $B = \{ (i, R_i, S_i) \}_{i \in \S}$,
each party $\partyid$ retrieves $(r_{\partyid}, s_{\partyid})$ from their internal state such that $(R_\partyid, S_\partyid) = (g^{r_{\partyid}}, g^{s_{\partyid}})$.
(The party aborts if such $(r_{\partyid}, s_{\partyid})$ does not exist.)
Then, each party derives binding factors $\bindingfactor_i \gets \HashNon(i, \setCommit)$ for each party $i \in \coalition$, the group commitment $R \gets \prod_{i \in \coalition} R_{i} \cdot  S_{i}^{\bindingfactor_i}$, and the challenge
%\liz{This terminology isn't defined.}
%\chelsea{defined next}
$c \gets \HashSig(R, \pk, m)$.
Finally, each party outputs their signature share as
$z_\partyid \gets r_{\partyid} + s_{\partyid} \cdot \bindingfactor_\partyid + c \cdot \sk_\partyid \cdot \lambda_\partyid$,
where $\lambda_\partyid$ is the Lagrange coefficient,
%\liz{Define.}
%\chelsea{we can do that in the full version}
and deletes $(r_{\partyid}, s_{\partyid})$.


\paragraph{Combine.}
The coordinator derives the response $z = \sum_{i \in \coalition} z_i$.
The group commitment $R$ is derived as explained above.
The output signature $\sigma = (R,z)$ is a standard Schnorr signature,
and verifies under the (single-party) Schnorr verification algorithm.

\subsubsection{Security Properties.}
Security of any threshold signature scheme is defined by the notion of unforgeability,
assuming the adversary is able to corrupt fewer than a threshold number of participants.
FROST achieves a strong notion of unforgeability in the dishonest majority setting,
under the algebraic one-more discrete logarithm (AOMDL) assumption in the random oracle model (ROM).
Intuitively, unforgeability in a threshold signature setting guarantees that an adversary which corrupts the coordinator and up to $t-1$ signers cannot generate a valid signature for any message $\msg$ that has not been signed by at least one honest signer.
As demonstrated by Bellare et al.~\cite{BellareCKMTZ22}, there are different conditions to declare $\msg$ to be authorized (signed),
which gives different security levels for partially non-interactive schemes such as FROST.
%\liz{These are only definitions for partially non-interactive schemes.  Also, we are proposing the fully two-round scheme.}
%\chelsea{it can be used in the one-round setting too}

%\chelsea{It would be helpful to emphasize that basic unforgeability is achieved by $\TSUF{0}$, and that each higher level gives finer-grained guarantees.}

\medskip

\textbf{TS-UF-0.} The weakest condition,
which gives the weakest unforgeability for a threshold signature scheme,
is referred to as $\TSUF{0}$, considers that $\msg$ was signed as long as at least one honest party generated a signature share for $\msg$.
In other words, for a $\TSUF{0}$-secure scheme, the adversary cannot forge a valid signature for $\msg$ if no honest party generated a signature share for $\msg$.
In the setting of FROST,
this condition entails that at least one honest signer output a response $z_i$ for a message $m$,
if the output signature under $\pk$ is valid.
$\TSUF{0}$ however does not consider the case when the adversary corrupts \emph{fewer} than $(t-1)$ parties,
i.e., it assumes that the number of corrupted parties $\numcorrupt = t-1$.

\medskip

\textbf{TS-UF-1.} The next level of security, $\TSUF{1}$, strengthens the above condition to requiring that at least  $(t - \numcorrupt)$ honest parties generated signature shares for $\msg$,
where $\numcorrupt$ denotes the number of corrupted parties,
such that $\numcorrupt \leq t$.
In other words,
$\TSUF{1}$ considers the generalized setting when the adversary corrupts $\numcorrupt < t-1$;
i.e., fewer parties than the maximum allowed $t-1$.

However, $\TSUF{1}$ does not guarantee that when the honest parties generated the signature shares for $\msg$, they all had the same view, i.e., received the same second-round input.
%igning coalition and the same combinations of commitments.
  %forwarding inconsistent information to different honest parties in the second (online) round.
%combining signature shares from different signing sessions.
More precisely, for a $\TSUF{1}$-secure scheme, the corrupted coordinator can send different combinations of commitments to different honest parties for signing $\msg$ in the (online) second round,
and as long as the total number of honest parties responded is at least $(t-\numcorrupt)$, the adversary might be able to compute a valid signature for $\msg$.

%\chelsea{Wouldn't this result in a ROS attack, and thus break unforgeability altogether?}

\medskip

\textbf{TS-UF-2.}
Such a malicious behavior is prevented by $\TSUF{2}$, where
we consider $\msg$ to be signed only if at least $(t - \numcorrupt)$ honest parties generated signature shares for $\msg$ and they received the same commitment combination when generating the shares.

\medskip

\textbf{TS-UF-3.} Bellare et al.~\cite{BellareCKMTZ22} showed that under the algebraic one-more discrete logarithm (AOMDL) assumption, the FROST achieves the next level of security, $\TSUF{3}$, in the random oracle model (ROM), where the above condition is further strengthened:
we declare $\msg$ to be signed only if there exists \liz{is} a coalition $\coalition$ and $\setCommit=\{ (i, R_{i}, S_{i})\}_{i \in \coalition}$ such that not only  $(t - \numcorrupt)$ honest parties, but also all honest parties $i\in \coalition$ with \emph{correct} $(R_{i}, S_{i})$, generated signature shares \liz{?} for the same secound-round input $(\msg, \setCommit)$, where we say $(R_{i}, S_{i})$ is correct if and only if it was output by party $i$ in Round 1.\footnote{Since the coordinator was corrupted, the commitment $(R_{i}, S_{i})$ might not be one of the commitments output by honest party $i$ in Round 1.}

%Namely, for a signing session with coalition $\coalition$ and second-round input $\{ (i, R_{i,\eid}, S_{i,\eid})\}_{i \in \coalition}$,
%in additional to the above condition, it is also required that each
%$(R_{i,\eid}, S_{i,\eid})$ that is input into Round 2 is in fact a correct commitment output by honest signer $i$ in Round 1 (i.e., $(R_{i,\eid}, S_{i,\eid})$ is the first-round commitment output by signer $i$).
%\chelsea{edited this for clarity, please review to make sure it is correct.}

\medskip

\textbf{TS-UF-4.}
The strongest notion of security defined by Bellare et al.~\cite{BellareCKMTZ22} is $\TSUF{4}$,
which requires that there is a coalition $\coalition$ and $\setCommit=\{ (i, R_{i}, S_{i})\}_{i \in \coalition}$ such that all honest parties in $\coalition$ generated  signature shares  $z_i$ for $(\msg, \setCommit)$.
$\TSUF{4}$ is a stronger condition because the size of $\coalition$ is at least $t$ and thus the number of honest parties in $\coalition$ is at least  $(t - \numcorrupt)$.
One means to achieve $\TSUF{4}$ security is by ensuring authenticity of participants' messages,
to prevent an adversary from performing integrity attacks that may result in a valid output signature but where participants' views are inconsistent during the protocol execution.

Bellare et al.~\cite{BellareCKMTZ22} showed that if we assume authenticated network channels, which guarantee that the corrupted coordinator cannot forward incorrect commitments to honest parties in the online round,
then FROST achieves $\TSUF{4}$.
However, because implementations may wish to define authenticated channels in a manner specific to their setup,
we do not define this authentication layer within this specification.
As such,
we allow implementations to choose if they wish to achieve $\TSUF{4}$ security,
and simply recommend that FROST be performed over an authenticated channel to do so.

\medskip
\textbf{Strong unforgeability.} Moreover, Bellare et al.~\cite{BellareCKMTZ22} showed that FROST is \emph{strongly} unforgeable, referred to as $\TSSUF{3}$ (or $\TSSUF{4}$ assuming authenticated channels), which, analogous to the strong unforgeability of signature schemes, guarantees that an adversary cannot forge a message-signature pair $(\msg,\sigma)$ that is not considered  authorized.
Also, it is guaranteed that there is at most one signature $\sigma$ that can be issued for each second-round input $(\msg, \setCommit=\{ (i, R_{i}, S_{i})\}_{i \in \coalition})$, and $(\msg, \sigma)$ is considered issued only if there are \emph{sufficiently many} honest parties that generated signature shares for $(\msg, \setCommit)$.
In particular, for $\TSSUF{3}$, ``sufficiently many honest parties'' includes all honest parties $i\in \coalition$ with \emph{correct} $(R_{i}, S_{i})$, and the total number of honest parties must be at least $(t - \numcorrupt)$; for $\TSSUF{4}$, ``sufficiently many honest parties'' refers to all honest parties in $\coalition$.

\medskip
\textbf{Adaptive security.} Crites et al.~\cite{adp-frost} analyze the adaptive security of FROST, which means that the adversary can adaptively choose which signers to corrupt even after learning the public key and participating in signing interactions. Upon corrupting a signer, the adversary learns all of the signer's internal state, including its signing key share and any nonces it has generated. They show that FROST achieves adaptive $\TSUF{0}$ under the AOMDL assumption in the random oracle model (ROM) when the maximum number of corrupted signers satisfies $t_c = t/2$. Furthermore, when $t_c > t/2$, they prove that FROST remains adaptively $\TSUF{0}$-secure under the additional assumption of the hardness of the low-dimensional vector representation (LDVR) problem—a new hardness assumption introduced in their work. They also show that, in certain parameter regimes, the LDVR problem is unconditionally hard.


%FROST is statically secure assuming fewer than $t$ parties are corrupted,
%and the algebraic one-more discrete logarithm (AOMDL) assumption holds in the random oracle model (ROM).

%TODO: add a summary here of different TS-UF levels.
